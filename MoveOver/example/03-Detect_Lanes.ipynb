{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move over project demo\n",
    "This notebook is the first attempt of applying detection and tracking system for move over projets\n",
    "- objects are detected and tracked\n",
    "- objects are visualized in the map\n",
    "- objects at lanes are counted\n",
    "- objects that changed lanes are counted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "sys.path.insert(0,'../..')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from time import time\n",
    "from cav.objects import Object, BoundingBox, ObjectType\n",
    "from cav.parameters import Parameters\n",
    "from cav.lanes import Lanes\n",
    "\n",
    "from cav.visualization import Map, plotBoxes\n",
    "\n",
    "# Deep sort imports\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort.detection import Detection\n",
    "%matplotlib inline \n",
    "\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOPOINT = 'BC'  ### Default value, Bottom center\n",
    "#TOPOINT = 'BR5' ## Bottom Right\n",
    "TOPOINT = 'BL10' ## Bottom Left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moveoverlib.helper import ImageEncoder, create_box_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_encoder = ImageEncoder(config.ENCODER_PATH, config.ENCODER_INPUT_NAME, config.ENCODER_OUTPUT_NAME)\n",
    "encoder = create_box_encoder(config.ENCODER_PATH, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.2\n",
    "nn_budget = 100\n",
    "\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "    \"cosine\", max_cosine_distance, nn_budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create params and map objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters()\n",
    "params.generateParameters('./params.json')\n",
    "mymap = Map('./images/SkyView.jpg', './icons_simple.json', params)\n",
    "plt.imshow(mymap.getMap(), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cav.lanes import Lanes\n",
    "lanes_controller = Lanes('./images/mask.png', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DETECTIONS = f'{config.DATA_PATH}/detections.p'\n",
    "FRAME_FOLDER = os.path.join(config.DATA_PATH, 'frames_raw/')\n",
    "VIDEO_FILE = pickle.load(open(f'{config.DATA_PATH}/videopath.p', 'rb'))\n",
    "print ('Video path:', VIDEO_FILE)\n",
    "\n",
    "Path(FRAME_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_detections = pickle.load(open(SAVE_DETECTIONS,'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOG = None #### Saves logs with all detected objects (path to file or none)\n",
    "\n",
    "SAVE_LANES = None ###### Saves info about lanes\n",
    "SAVE_LANES = './data/lanes_detections.csv' ###### Saves info about lanes\n",
    "\n",
    "SKIP_FIRST = 0 # How many seconds in the beginning should be skipped\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_FILE) \n",
    "FRAMES_SEC = cap.get(cv2.CAP_PROP_FPS)\n",
    "VIDEO_X = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "VIDEO_Y = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) \n",
    "\n",
    "\n",
    "MAX_BOXES_TO_DRAW = 100\n",
    "MIN_SCORE_THRESH = 0.5\n",
    "IOU_COMMON_THRESHOLD = 0.50\n",
    "NOT_DETECTED_TRHESHOLD = 1\n",
    "\n",
    "MAPSHAPE = mymap.getMap().shape\n",
    "print ('Y dimension of map is {:.3f} larger than Y dimension of the video'\n",
    "      .format(MAPSHAPE[0] / VIDEO_Y))\n",
    "\n",
    "MAP_RESIZE = 3\n",
    "\n",
    "print ('Y dimension of map is {:.3f} larger than Y dimension of the video. Size of the map is reduced {} times.'\n",
    "      .format(MAPSHAPE[0] / VIDEO_Y, MAP_RESIZE))\n",
    "\n",
    "\n",
    "FINAL_X = VIDEO_X + int(MAPSHAPE[1] / MAP_RESIZE)\n",
    "FINAL_Y = max(VIDEO_Y, int(MAPSHAPE[0] / MAP_RESIZE))\n",
    "\n",
    "print ('Video size: [{}, {}], Final size: [{}, {}]'\n",
    "      .format(VIDEO_X, VIDEO_Y, FINAL_X, FINAL_Y))\n",
    "\n",
    "RESIZE = False\n",
    "\n",
    "\n",
    "CROP_VID = False\n",
    "VID_LEFT = 0\n",
    "VID_RIGHT = 1920\n",
    "VID_UP = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (MAPSHAPE[0] / VIDEO_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_FILE) \n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "out = None\n",
    "\n",
    "objects = []\n",
    "\n",
    "results = []\n",
    "colors = {}\n",
    "\n",
    "\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "\n",
    "\n",
    "nr_skipped = 0\n",
    "i = 0\n",
    "t = time()\n",
    "\n",
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    \n",
    "    if SAVE_LANES is not None:\n",
    "        logfile_lanes = open('{}'.format(SAVE_LANES), 'w')\n",
    "\n",
    "    while cap.isOpened():\n",
    "        t2 = time() - t\n",
    "        sys.stdout.write('{} frames done in {:.1f} seconds ({:.2f} frames/sec)    \\r'.format(\n",
    "            i, t2, i/t2))                   \n",
    "        \n",
    "        \n",
    "        frame_timeStamp = i/FRAMES_SEC\n",
    "        \n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if i < SKIP_FIRST * FRAMES_SEC:\n",
    "            i += 1\n",
    "            continue\n",
    "                \n",
    "        \n",
    "        if CROP_VID:\n",
    "            image = image[VID_UP:, VID_LEFT:VID_RIGHT, :]\n",
    "        \n",
    "        if i+1 not in save_detections:\n",
    "            break\n",
    "        \n",
    "        boxes, scores, classes = save_detections[i+1] \n",
    "        \n",
    "        if len(boxes) >= 1:\n",
    "            for box in boxes:\n",
    "                if TOPOINT != 'BC':\n",
    "                    box.setToPoint(TOPOINT)\n",
    "                    \n",
    "                box.updateParams(params)\n",
    "                \n",
    "            boxes_array = [[box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop] for box in boxes]\n",
    "            boxes_array = np.array(boxes_array)\n",
    "            bgr_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            features = encoder(bgr_image, boxes_array)\n",
    "            detections = []\n",
    "\n",
    "            for box, score, objClass, f_vector in zip(boxes, scores, classes, features):\n",
    "                detection = Detection(\n",
    "                    [box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop], #BBox\n",
    "                    score, f_vector,\n",
    "                    objClass\n",
    "                )\n",
    "                detection.bbox = box\n",
    "                detections.append(detection)\n",
    "\n",
    "            tracker.predict()\n",
    "            tracker.update(detections)                \n",
    "            \n",
    "        else:\n",
    "            tracker.predict()\n",
    "            \n",
    "        plotboxes = []\n",
    "        plotcolors = []\n",
    "        objects = []\n",
    "\n",
    "        if len(tracker.tracks) >= 1:\n",
    "            for track in tracker.tracks:\n",
    "                if not track.is_confirmed() or track.time_since_update >= 1:\n",
    "                    continue\n",
    "\n",
    "                obj = track.trackedObject\n",
    "\n",
    "                if obj is not None:\n",
    "                    if obj.color is None:\n",
    "                        obj.color = (randint(0, 255), randint(0, 255), randint(0, 255))                        \n",
    "                    plotbox = obj.bboxes[-1]\n",
    "                    plotbox.trackId = track.track_id\n",
    "                    plotboxes.append(plotbox)\n",
    "                    plotcolors.append(obj.color)\n",
    "                    objects.append(obj)\n",
    "                    \n",
    "                    if SAVE_LANES is not None:\n",
    "                        lane = lanes_controller.addObject(obj)\n",
    "                        if SAVE_LANES is not None:\n",
    "                            log_line = '{},{},{}'.format(i, lane, obj.getParams(asCsv=True, speedLookback = 10))\n",
    "                            print(log_line,file=logfile_lanes)                              \n",
    "\n",
    "                                                         \n",
    "            if len(plotboxes) >= 1:\n",
    "                vid = plotBoxes(image, plotboxes, colors=plotcolors)\n",
    "            else:\n",
    "                vid = image.copy()\n",
    "            cv2.imwrite(os.path.join(FRAME_FOLDER, 'im_{}.jpg'.format(str(i).zfill(6))), vid)\n",
    "\n",
    "\n",
    "                \n",
    "        if len(objects) > 0:\n",
    "                                \n",
    "            if SAVE_LOG is not None:\n",
    "                logfile = open('./logs/{}'.format(SAVE_LOG, 'w'))\n",
    "                for obj in objects:\n",
    "                    line = '{},{},{}'.format(i,time(),obj.getParams(asCsv=true))                               \n",
    "                    print(line,file=logfile)                    \n",
    "                                \n",
    "        i = i+1\n",
    "                \n",
    "            \n",
    "                        \n",
    "t = time() - t                             \n",
    "print('\\n\\n{} frames done in {:.1f} seconds ({:.2f} frames/sec)'.format(\n",
    "    i, t, i/t))                             \n",
    "cap.release()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
